{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Midterm analysis (with Pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Grade frequencies on 2020.12.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "grades = {\n",
    "#   'Nota': [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "    'LE': [1,0,2,1,1,1,0,2,1,1,0,3,2,1,7,0,6,2,12,15,169],\n",
    "    'RE': [2,0,1,3,0,1,0,0,0,1,1,0,4,1,1,3,5,9,24,119,50],\n",
    "    'PE': [2,0,0,4,1,3,1,5,10,4,7,9,13,29,21,16,23,8,22,5,37]\n",
    "}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Create a data frame from a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(grades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If not inside a Jupyter.notebooks, import matplotlib as well\n",
    "\n",
    "`import matplotlib.pyplot as plt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How many grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#df[['LE', 'RE', 'PE']].sum()\n",
    "df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.sum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Plot PE, RE, LE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df['PE'].plot(kind='bar', title='PE Grades', xticks=[0, 4, 8, 12, 16, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df['RE'].plot(kind='bar', title='RE Grades', xticks=[0, 4, 8, 12, 16, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df['LE'].plot(kind='bar', title='LE Grades', xticks=[0, 4, 8, 12, 16, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.plot(kind='bar', title='All Grades', yticks=[50, 100, 150], xticks=[0, 4, 8, 12, 16, 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Show stats (over frequencies?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## Mean\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## Median\n",
    "df.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Not relevant because we have frequencies!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "But, maybe a Kolmogorov-Smirnov test for goodness of fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def freqs_to_sample(freqs): \n",
    "    return [i for i, f in enumerate(freqs) for _ in range(f)]\n",
    "#freqs_to_sample(df['LE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import kstest\n",
    "kstest(freqs_to_sample(df['LE']), 'norm')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "ks_2samp(freqs_to_sample(df['LE']), freqs_to_sample(df['PE']))[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## And the image is clear!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['LE'].plot(kind='area', title='Cristal clear!', xticks=[0, 4, 8, 12, 16, 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Formative vs Summative assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Formative\n",
    "\n",
    "> **The purpose of formative assessment is to monitor student learning and provide ongoing feedback to staff and students**.\n",
    "\n",
    "> It is assessment for learning.\n",
    "\n",
    "> If designed appropriately, it helps students identify their strengths and weaknesses, can enable students to improve their self-regulatory skills so that they manage their education in a less haphazard fashion than is commonly found.\n",
    "\n",
    "[Leaning & Teaching at Greenwich](https://www.gre.ac.uk/learning-teaching/assessment/assessment/design/formative-vs-summative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Summative\n",
    "\n",
    "> **The goal of summative assessment is to evaluate student learning at the end of an instructional unit by comparing it against some standard or benchmark**. \n",
    "\n",
    "> Summative assessments often have high stakes and are treated by the students as the priority over formative assessments.\n",
    "\n",
    "> However, feedback from summative assessments can be used formatively by both students and faculty to guide their efforts and activities in subsequent courses.\n",
    "\n",
    "[Leaning & Teaching at Greenwich](https://www.gre.ac.uk/learning-teaching/assessment/assessment/design/formative-vs-summative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conclusões (in Portuguese now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Avaliação LE em COVID\n",
    "\n",
    "> A análise das classificações a meio do semestre mostra que, em condições diferentes daquelas para as quais foi desenhada, a avaliação LE não cumpre o propósito:\n",
    "\n",
    "- não dá ao professor qualquer feedback válido sobre assuntos que tenham de ser revistos\n",
    "- não dá ao estudante uma ideia clara dos assuntos que tem de rever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Alteração de LE de Sumativa a Formativa\n",
    "> Esta parcela da avaliação deve passar de \"Sumativa\" a \"Formativa\" e não deve contar para a nota final do estudante. \n",
    "\n",
    "> Vou incluir esta alteração na secção de Observações da Ficha, com o título de \"Alterações COVID\", e propor uma modificação na fórmula de cálculo, para passar a ser:\n",
    "\n",
    "Classificação final = 0 * LE + 10 * RE + 55 * PE + 35 * TE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A avaliação especial (TE, DA, …) mantém-se nos moldes atuais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Nesta data, as respostas erradas passam a descontar 1/4 do valor da pergunta.**"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
